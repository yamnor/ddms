---
title: 📙 クイズ
---

## データ駆動型アプローチの戦略的意義

### データ生成装置としての役割

{{< quiz >}}
マテリアルズ・インフォマティクスにおいて、既存の実験データベースではなく、あえて第一原理計算でデータを生成する最大の戦略的メリットは何でしょうか？

* [ ] 自然界に存在する物質の実験値を、測定誤差なく完全に再現できるため
* [x] 実験では合成困難な不安定相や仮想物質を含めた「空白領域」に対し、物理法則に基づいた均質でバイアスのないデータを網羅的に生成できるため
* [ ] 計算データを用いることで、機械学習モデルの解釈可能性（XAI）が自動的に保証されるため
* [ ] 第一原理計算は量子コンピュータを使用するため、計算速度が実験よりも圧倒的に速いため
{{< /quiz >}}

### ネガティブデータの価値

{{< quiz >}}
ターゲットとする特性が出なかった「失敗データ」や「構造不安定なデータ」を、機械学習の学習データに含めるべき理由として、最も適切なものはどれですか？

* [ ] データ数が多ければ多いほど、モデルの種類に関わらず無条件に性能が向上するため
* [ ] 将来的に計算手法が進化すれば、それらが安定な構造に変化する可能性があるため
* [x] 探索空間における「有望領域」と「不適領域」の決定境界を学習させ、モデルが物理的にあり得ない予測をするのを防ぐため
* [ ] 実験データ不足を補うためのノイズ（Data Augmentation）として機能させるため
{{< /quiz >}}

## 理論的背景と物理的解釈

### 全エネルギーの基準

{{< quiz >}}
第一原理計算で出力される全エネルギー（Total Energy）の値（例：-540.2 eV）の解釈について、正しい記述はどれですか？

* [ ] 絶対的なエネルギー値であり、異なる擬ポテンシャルやソフトウェア間で値を直接比較できる
* [ ] 値が負（マイナス）であることは、その系が物理的に不安定であることを示している
* [x] その計算設定内での基準状態（孤立原子など）からの相対値であり、同一の設定で計算された系同士の「エネルギー差」にのみ物理的な意味がある
* [ ] 絶対零度における値ではなく、室温（300K）における自由エネルギーを表している
{{< /quiz >}}

### 実験値との乖離（有限温度効果）

{{< quiz >}}
一般的なDFT計算（0K）で求めた格子定数が、室温の実験値と比較して過小評価（または過大評価）される場合、その物理的背景として考慮すべき主要因はどれですか？

* [ ] 計算機の桁落ち誤差による数値的な精度不足
* [ ] 実験サンプルの純度が低く、測定値が間違っている可能性が高い
* [x] 交換相関汎関数の近似に加え、計算に含まれない「熱膨張」や「零点振動」の影響
* [ ] SCFサイクルの収束基準が緩すぎたため、最安定構造に到達していない
{{< /quiz >}}

### SCFサイクルの本質

{{< quiz >}}
第一原理計算の内部ループであるSCF（Self-Consistent Field）サイクルにおいて、反復計算によって収束（最適化）させている物理量は何ですか？

* [ ] 原子核の空間座標（原子位置）
* [x] 電子密度分布と、それによって決定される有効ポテンシャル
* [ ] ブリルアンゾーン内のk点の数
* [ ] 波動関数の基底関数の数（カットオフエネルギー）
{{< /quiz >}}

## 計算条件とデータ品質管理

### 収束テストの目的

{{< quiz >}}
未知の材料系に対して、カットオフエネルギーやk点メッシュの「収束テスト」を行う、最も科学的な理由はどれですか？

* [ ] 計算時間が最も短くなる最適なパラメータを見つけるため
* [x] 計算パラメータの設定不足による数値的な誤差を飽和させ、物理的なエネルギー差を議論できる精度を保証するため
* [ ] 論文に掲載する際、デフォルト設定ではないことをアピールするため
* [ ] 擬ポテンシャルファイルが破損していないか確認するため
{{< /quiz >}}

### 異種データの混合リスク

{{< quiz >}}
複数のデータベース（例：Materials ProjectとAFLOW）からデータを統合して機械学習を行う際、物理的に最も致命的なエラーを引き起こす要因はどれですか？

* [ ] データの保存形式（JSONとXML）が混在している
* [ ] 結晶構造の記述方法（Primitive CellとConventional Cell）が統一されていない
* [x] 使用された「交換相関汎関数」や「擬ポテンシャル」が異なり、エネルギーの基準点がずれているため、形成エネルギーの比較が無意味になる
* [ ] 計算を実行した日付が異なり、使用したCPUの性能差が反映されてしまう
{{< /quiz >}}

## 機械学習との連携（Advanced）

### 代理モデル（Surrogate Model）の適用限界

{{< quiz >}}
第一原理計算データを学習した代理モデルを用いて、未知の材料をスクリーニングする際の「外挿（Extrapolation）」のリスクについて、正しい認識はどれですか？

* [ ] 物理法則（シュレーディンガー方程式）を学習しているため、未知の元素や構造であっても正確に予測できる
* [ ] 予測精度は落ちるが、物理的にあり得ない値が出力されることはない
* [x] 学習データの分布から外れた化学組成や構造に対しては、予測精度が保証されず、信頼度（Uncertainty）の評価が不可欠である
* [ ] ニューラルネットワークの層を深くすれば、外挿領域の予測精度は解決される
{{< /quiz >}}

### Delta Learning（差分学習）

{{< quiz >}}
計算値と実験値の間に乖離がある場合、高精度な予測モデルを作るための現代的な手法（Delta Learning）のアプローチはどれですか？

* [ ] 計算データは信頼性が低いためすべて破棄し、実験データのみで学習する
* [x] 大量の「計算データ（低精度）」で大まかな傾向を学習し、少数の「実験データ（高精度）」との差分（残差）を学習させて補正する
* [ ] 実験値を計算値に合うように補正してから学習させる
* [ ] 計算のパラメータをランダムに変えて、実験値に合う計算結果が出るまで探索する
{{< /quiz >}}

### 自律的探索（Active Learning）

{{< quiz >}}
データが少ない初期段階から効率的に新材料を発見するために、AIが計算や実験の条件を提案する「アクティブラーニング」において、次に探索すべき点として選ばれるのはどのようなデータですか？

* [ ] 既存のデータと最も類似しており、確実に予測が当たりそうなデータ
* [ ] 予測値のスコアが最も高いデータだけを選び続ける
* [x] 予測の期待値が高いデータ、またはモデルの予測不確実性が高く「情報獲得効果」が大きいデータ
* [ ] ランダムに選ばれたデータ
{{< /quiz >}}

## データエコシステムと未来

### FAIR原則と機械可読性

{{< quiz >}}
FAIR原則に基づき、計算結果と共にメタデータ（入力ファイル、ログ、バージョン情報）を構造化して保存する最大の目的は、現代のデータ科学において何とされていますか？

* [ ] 研究不正が行われていないことを証明するため
* [x] 人間の介入なしに、AIエージェントやプログラムが自律的にデータを検索・解釈・再利用できる「Machine Actionability」を確保するため
* [ ] データのファイルサイズを圧縮し、ストレージコストを下げるため
* [ ] 将来、特許申請を行う際の証拠能力を高めるため
{{< /quiz >}}

### 自動化ワークフローとエラー処理

{{< quiz >}}
ハイスループット計算においてSCF収束エラーが発生した際、手動介入を減らすための最新のワークフローシステムがとる挙動はどれですか？

* [ ] エラーが出た計算は即座に停止し、管理者にメールで通知して終了する
* [ ] エラーを無視して、最後のステップのエネルギー値を強制的に出力する
* [x] 事前定義された対処ロジック（Custodian/Agent）に基づき、混合パラメータやアルゴリズムを自動調整して再計算を試みる
* [ ] エラーが発生した物質は、物理的に存在しないと判断してデータベースから削除する
{{< /quiz >}}
